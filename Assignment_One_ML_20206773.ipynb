{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a988479e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB, CategoricalNB\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from collections import Counter\n",
    "import math\n",
    "from sklearn.metrics import accuracy_score\n",
    "from math import exp, pi, sqrt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1faa526",
   "metadata": {},
   "source": [
    "# Implementation of Gaussian Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c39b2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyGaussianNB(BaseEstimator, ClassifierMixin):          \n",
    "    def fit(self, Xt, yt):\n",
    "        \n",
    "        self.Xt = pd.DataFrame(Xt)\n",
    "        self.yt = pd.DataFrame(yt)\n",
    "        \n",
    "        #convert data types \n",
    "        for i in range(0,len(self.Xt.columns)):\n",
    "            self.Xt[i] = self.Xt[i].astype(type(self.Xt[i][0]))\n",
    "        \n",
    "        #getting the class probabilities\n",
    "        c_dict = Counter(yt)\n",
    "        total = sum(c_dict.values())\n",
    "        self.class_prob_dict = {}\n",
    "        for item in c_dict:\n",
    "            self.class_prob_dict[item] = (c_dict[item]/total)\n",
    "            \n",
    "    \n",
    "        #creating dictionary of conditional probabilities for the categorical features and storing \n",
    "        \n",
    "        #concatenating x and y to get the full dataframe \n",
    "        full_df = pd.concat([self.yt,self.Xt], axis=1, ignore_index=True)\n",
    "        #creating a list of the indices of the categorical features\n",
    "        categorical = full_df.select_dtypes(exclude=[float]).columns.delete(0)\n",
    "        self.conditional_probs = {}\n",
    "        \n",
    "        #iterating over each categorical feature \n",
    "        for item in categorical:\n",
    "            self.conditional_probs[item] = (full_df.groupby(by=[0])[item].value_counts()/ full_df.groupby(by=[0])[item].count())        \n",
    "\n",
    "            \n",
    "        #getting the mean and standard deviation of each class for each numeric features and storing\n",
    "        classes = self.yt[0].unique()\n",
    "        numeric = full_df.select_dtypes(include=[float]).columns\n",
    "        \n",
    "        self.class_dict = {}\n",
    "        \n",
    "        #iterating over each numerical feature and then iterating over each class within that feature\n",
    "        #appending the mean and standard deviation for each class to a dictionary \n",
    "        for item in numeric:\n",
    "            numeric_dict = {}\n",
    "            for thing in classes:\n",
    "                class_item = full_df[full_df[0] == thing][item]\n",
    "                numeric_dict[thing] = {'mean':class_item.mean(),'std':class_item.std()}\n",
    "\n",
    "            self.class_dict[item] = numeric_dict\n",
    "            \n",
    "        return self\n",
    "    \n",
    "    def predict(self, Xtest):\n",
    "        self.Xtest = pd.DataFrame(Xtest)\n",
    "        \n",
    "        #convert data types \n",
    "        for i in range(0,len(self.Xtest.columns)):\n",
    "            self.Xtest[i] = self.Xtest[i].astype(type(self.Xtest[i][0]))\n",
    "        \n",
    "        #iterating over each row of the dataframe \n",
    "        #creating a dictionary of lists for each row for each class and getting the product of these lists\n",
    "        #checking which product is the largest and returning that class as the predicted class\n",
    "        final_result_array = []\n",
    "        big_dict = {}\n",
    "        \n",
    "        for index, row in self.Xtest.iterrows():\n",
    "            classes = self.yt[0].unique()\n",
    "            results = {}\n",
    "\n",
    "            for item in classes:\n",
    "                results[item] = []\n",
    "                results[item].append(self.class_prob_dict[item])\n",
    "                \n",
    "                #iterating over each value in the row \n",
    "                for i in range(0, len(self.Xtest.columns)):\n",
    "                    try:\n",
    "                        #if numeric, access the dictionary of means and std dev and plug values into \n",
    "                        #the probability function \n",
    "                        if type(row[i]) == np.float64 or type(row[i]) == float:\n",
    "                            results[item].append(self.calculate_probability(row[i],self.class_dict[i+1][item]['mean'],self.class_dict[i+1][item]['std']))\n",
    "                        \n",
    "                        #if categorical, access the dictionary of conditional probabilities created in fit()\n",
    "                        else:\n",
    "                            results[item].append(self.conditional_probs[i+1][item][row[i]])\n",
    "                            \n",
    "                    # exception occurs in cases where feature isn't present in a particualr class\n",
    "                    # in this case the value filled in is zero \n",
    "                    except:\n",
    "                        results[item].append(0)\n",
    "                \n",
    "                big_dict[item] = np.prod(results[item])  \n",
    "                \n",
    "            final_result_array.append(max(big_dict, key=big_dict.get))\n",
    "            \n",
    "        return final_result_array\n",
    "    \n",
    "    # probability function \n",
    "    def calculate_probability(self, x, mean, stdev):\n",
    "        exponent = exp(-((x-mean)**2 / (2 * stdev**2 )))\n",
    "        return (1 / (sqrt(2 * pi * stdev**2)) * exponent)   \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651d4e4a",
   "metadata": {},
   "source": [
    "# Testing using variety of datasets\n",
    "\n",
    "## Penguins Data Set (Numerical and Categorical features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73ba6270",
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins_af = pd.read_csv('penguins_af.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3781d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = penguins_af.pop('species').values\n",
    "X = penguins_af.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47a6146d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=2, test_size=1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee4c89d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "GBC = MyGaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "492c65fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MyGaussianNB()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GBC.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f65dbabe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2: {'Chinstrap': {'mean': 48.9764705882353, 'std': 3.1156553689226625},\n",
       "  'Gentoo': {'mean': 47.78928571428569, 'std': 2.9531910981745937},\n",
       "  'Adelie': {'mean': 38.922368421052624, 'std': 2.658149666426405}},\n",
       " 3: {'Chinstrap': {'mean': 18.66176470588235, 'std': 1.120339425266953},\n",
       "  'Gentoo': {'mean': 15.014285714285716, 'std': 0.9964352045582884},\n",
       "  'Adelie': {'mean': 18.293421052631576, 'std': 1.2699958557744235}},\n",
       " 4: {'Chinstrap': {'mean': 196.85294117647058, 'std': 6.592614568205835},\n",
       "  'Gentoo': {'mean': 217.625, 'std': 7.636187768537625},\n",
       "  'Adelie': {'mean': 189.25, 'std': 6.515878042648333}},\n",
       " 5: {'Chinstrap': {'mean': 3736.764705882353, 'std': 405.93304857907145},\n",
       "  'Gentoo': {'mean': 5075.892857142857, 'std': 517.861956986132},\n",
       "  'Adelie': {'mean': 3695.3947368421054, 'std': 479.00435847557435}}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GBC.class_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7bb46d57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Chinstrap',\n",
       " 'Gentoo',\n",
       " 'Adelie',\n",
       " 'Gentoo',\n",
       " 'Adelie',\n",
       " 'Adelie',\n",
       " 'Gentoo',\n",
       " 'Adelie',\n",
       " 'Adelie',\n",
       " 'Adelie',\n",
       " 'Adelie',\n",
       " 'Adelie',\n",
       " 'Gentoo',\n",
       " 'Adelie',\n",
       " 'Adelie',\n",
       " 'Chinstrap',\n",
       " 'Adelie',\n",
       " 'Gentoo',\n",
       " 'Adelie',\n",
       " 'Gentoo',\n",
       " 'Gentoo',\n",
       " 'Gentoo',\n",
       " 'Chinstrap',\n",
       " 'Gentoo',\n",
       " 'Gentoo',\n",
       " 'Adelie',\n",
       " 'Gentoo',\n",
       " 'Chinstrap',\n",
       " 'Adelie',\n",
       " 'Gentoo',\n",
       " 'Adelie',\n",
       " 'Adelie',\n",
       " 'Adelie',\n",
       " 'Adelie',\n",
       " 'Gentoo',\n",
       " 'Gentoo',\n",
       " 'Adelie',\n",
       " 'Adelie',\n",
       " 'Adelie',\n",
       " 'Chinstrap',\n",
       " 'Adelie',\n",
       " 'Chinstrap',\n",
       " 'Adelie',\n",
       " 'Gentoo',\n",
       " 'Gentoo',\n",
       " 'Adelie',\n",
       " 'Gentoo',\n",
       " 'Gentoo',\n",
       " 'Adelie',\n",
       " 'Gentoo',\n",
       " 'Gentoo',\n",
       " 'Chinstrap',\n",
       " 'Gentoo',\n",
       " 'Adelie',\n",
       " 'Chinstrap',\n",
       " 'Chinstrap',\n",
       " 'Gentoo',\n",
       " 'Adelie',\n",
       " 'Gentoo',\n",
       " 'Adelie',\n",
       " 'Gentoo',\n",
       " 'Chinstrap',\n",
       " 'Chinstrap',\n",
       " 'Adelie',\n",
       " 'Chinstrap',\n",
       " 'Adelie',\n",
       " 'Chinstrap',\n",
       " 'Adelie',\n",
       " 'Adelie',\n",
       " 'Gentoo',\n",
       " 'Gentoo',\n",
       " 'Gentoo',\n",
       " 'Adelie',\n",
       " 'Adelie',\n",
       " 'Chinstrap',\n",
       " 'Adelie',\n",
       " 'Chinstrap',\n",
       " 'Adelie',\n",
       " 'Gentoo',\n",
       " 'Gentoo',\n",
       " 'Gentoo',\n",
       " 'Adelie',\n",
       " 'Adelie',\n",
       " 'Gentoo',\n",
       " 'Gentoo',\n",
       " 'Adelie',\n",
       " 'Adelie',\n",
       " 'Gentoo',\n",
       " 'Chinstrap',\n",
       " 'Adelie',\n",
       " 'Adelie',\n",
       " 'Gentoo',\n",
       " 'Gentoo',\n",
       " 'Gentoo',\n",
       " 'Chinstrap',\n",
       " 'Gentoo',\n",
       " 'Gentoo',\n",
       " 'Gentoo',\n",
       " 'Chinstrap',\n",
       " 'Chinstrap',\n",
       " 'Gentoo',\n",
       " 'Adelie',\n",
       " 'Adelie',\n",
       " 'Chinstrap',\n",
       " 'Gentoo',\n",
       " 'Gentoo',\n",
       " 'Chinstrap',\n",
       " 'Gentoo',\n",
       " 'Adelie',\n",
       " 'Chinstrap',\n",
       " 'Gentoo',\n",
       " 'Gentoo',\n",
       " 'Gentoo',\n",
       " 'Adelie',\n",
       " 'Chinstrap',\n",
       " 'Adelie',\n",
       " 'Gentoo',\n",
       " 'Gentoo',\n",
       " 'Adelie',\n",
       " 'Adelie',\n",
       " 'Adelie',\n",
       " 'Gentoo',\n",
       " 'Adelie',\n",
       " 'Gentoo',\n",
       " 'Gentoo',\n",
       " 'Chinstrap',\n",
       " 'Adelie',\n",
       " 'Gentoo',\n",
       " 'Chinstrap',\n",
       " 'Adelie',\n",
       " 'Adelie',\n",
       " 'Adelie',\n",
       " 'Chinstrap',\n",
       " 'Gentoo',\n",
       " 'Adelie',\n",
       " 'Adelie',\n",
       " 'Chinstrap',\n",
       " 'Gentoo',\n",
       " 'Adelie',\n",
       " 'Gentoo',\n",
       " 'Adelie',\n",
       " 'Adelie',\n",
       " 'Chinstrap',\n",
       " 'Gentoo',\n",
       " 'Adelie',\n",
       " 'Adelie',\n",
       " 'Adelie',\n",
       " 'Adelie',\n",
       " 'Adelie',\n",
       " 'Adelie',\n",
       " 'Adelie',\n",
       " 'Adelie',\n",
       " 'Gentoo',\n",
       " 'Adelie',\n",
       " 'Adelie',\n",
       " 'Gentoo',\n",
       " 'Adelie',\n",
       " 'Gentoo',\n",
       " 'Gentoo',\n",
       " 'Adelie',\n",
       " 'Chinstrap',\n",
       " 'Chinstrap',\n",
       " 'Gentoo',\n",
       " 'Chinstrap',\n",
       " 'Gentoo',\n",
       " 'Gentoo',\n",
       " 'Adelie']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GBC.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ce8a299",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9820359281437125"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GBC.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40853ba5",
   "metadata": {},
   "source": [
    "A very high accuracy score of 98% is achieved when both categorical and numerical features are included. This indicates that the inclusion of the categorical features marginally improves the predictive power for the Gaussian Naive Bayes model for this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867c4c55",
   "metadata": {},
   "source": [
    "## Limiting to numerical features only \n",
    "\n",
    "We are aiming to test the performance of our implementation of the Gaussian Naive Bayes classifier against the sci kit learn implementation. Therefore we will limit the penguins dataset to numerical features only and test again. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2670af97",
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins = pd.read_csv('penguins_af.csv', index_col = 0)\n",
    "penguins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6b639e",
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins = penguins[['species', 'bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'body_mass_g']]\n",
    "penguins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b627a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = penguins.pop('species').values\n",
    "X = penguins.values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=2, test_size=1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1915cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "GBC = MyGaussianNB()\n",
    "GBC.fit(X_train,y_train)\n",
    "GBC.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d99b498",
   "metadata": {},
   "outputs": [],
   "source": [
    "GBC.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b788a654",
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train,y_train)\n",
    "gnb.predict(X_test)\n",
    "gnb.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c61b4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(GBC.predict(X_test), gnb.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2846567",
   "metadata": {},
   "source": [
    "The results produced from the MyGaussianNB implementation identically match those produced by the scikit learn implementation, both produce scores of 96%. This is a good sign as it shows our implementations is working as it should be. An accuracy score of 1.0 is produced showing that the model predicts the exact same values as the sklearn implementation on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e5f4a4",
   "metadata": {},
   "source": [
    "## Diabetes Data Set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6284ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes = pd.read_csv('diabetes.csv')\n",
    "diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0cfc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = diabetes.pop('neg_pos').values\n",
    "X = diabetes.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464cac1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=2, test_size=1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd495c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "GBC_diabetes = MyGaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1240947d",
   "metadata": {},
   "outputs": [],
   "source": [
    "GBC_diabetes.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368cca20",
   "metadata": {},
   "outputs": [],
   "source": [
    "GBC_diabetes.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad838f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "GBC_diabetes.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f717d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train,y_train)\n",
    "gnb.predict(X_test)\n",
    "gnb.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b37a49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(GBC_diabetes.predict(X_test), gnb.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5542620",
   "metadata": {},
   "source": [
    "Once again a very similar accuracy score is achieved for both our implementation (74%) and the scikit-learn implementation (73.7%). For this dataset, our model produced a marginally better result but this margin is neglible in the grand scheme of things. Once again this is an inidcator that our model is predicting to the same standard as the scikit learn model. An accuracy score of 99.4% is produced between our model and the sklearn implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e31839",
   "metadata": {},
   "source": [
    "## Glass Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491376f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "glass = pd.read_csv('glassV2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd094d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "glass['Type'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db064c6b",
   "metadata": {},
   "source": [
    "Due to the class imbalance here, we will remove Types 3,5 and 7 from the dataset such that it is a binary classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5401e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "glass = glass[glass.Type != 3]\n",
    "glass = glass[glass.Type != 5]\n",
    "glass = glass[glass.Type != 7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41df739e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = glass.pop('Type').values\n",
    "X = glass.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638ad893",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=2, test_size=1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51de8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "GBC_glass = MyGaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca22d6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "GBC_glass.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce70a1d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "GBC_glass.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5f8d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "GBC_glass.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab57579f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train,y_train)\n",
    "gnb.predict(X_test)\n",
    "gnb.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5359f0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(GBC_glass.predict(X_test), gnb.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2742a71",
   "metadata": {},
   "source": [
    "Once again a very similar score is achieved for both our implementation and the scikit-learn implementation. This result is only achieved after the class imbalance is dealt with, before dealing with this imbalance the sklearn model was producing a score around 35% and our model produced a score around 60%. An accuracy score of 1.0 is produced between our model and the sklearn implementation showing that they are predicting the exact same values on the test set."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
